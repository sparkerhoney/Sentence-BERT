{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수에서 OpenAI API 키와 조직 ID 가져오기\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai_organization = os.getenv('OPENAI_ORGANIZATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "openai.organization=\"org-uYykfT9G7rDF0QWyyl3XTUN5\"\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_system = \"\"\"\n",
    "LLM instruction for extraction\n",
    "The extraction result shapes this.\n",
    "Extractions = [Extraction] = [{FoundedEntity, Score}]\n",
    "Extraction = {FoundedEntity, Score} = {FoundedEntity JSON}, {How it is used well naturally, perfectly. The value has a range of 0.00~1.00}\n",
    "FoundedEntity = {Entity.entity, sub_type, usage_example, context_from_dialogue, reason_of_score}\n",
    "sub_type = vocabulary | phrasalVerb | idiom\n",
    "\n",
    "MISSION:\n",
    "Constraints 1. Extract the array of entities found in the user utterances from the dialogue.\n",
    "Constraints 2. The Final response must be the 'Extractions' without any descriptive words.\n",
    "Constraints 3. You must find well-used entities(higher than 0.65) and (not perfectly matched with context or ) poorly used  ones(lower than 0.35) simultaneously and as many as possible.\n",
    "Constraints 4. You must print the top 3 score dialogue\n",
    "\n",
    "extraxtion dialogue example is here.\n",
    "[example]\n",
    "[\n",
    "  {\n",
    "    \"FoundedEntity\": {\n",
    "      \"Entity.entity\": \"get the hang of\",\n",
    "      \"sub_type\": \"idiom\",\n",
    "      \"usage_example\": \"It was a bit challenging, especially the past perfect tense, but I think I'm getting the hang of it.\",\n",
    "      \"context_from_dialogue\": \"The student expressed understanding and acquiring skill in using past perfect tense through practice.\",\n",
    "      \"reason_of_score\": \"The idiom is used correctly within the context, indicating the process of understanding or mastering something through experience or practice.\"\n",
    "    },\n",
    "    \"Score\": 0.85\n",
    "  },\n",
    "  {\n",
    "    \"FoundedEntity\": {\n",
    "      \"Entity.entity\": \"   \",\n",
    "      \"sub_type\": \"phrasalVerb\",\n",
    "      \"usage_example\": \"\"takeoff\" means to remove something quickly, like a piece of clothing, but it can also mean to leave suddenly in the context of a plane \"takingoff.\"\",\n",
    "      \"context_from_dialogue\": \"The tutor explains the dual meanings of \"takeoff\" in different contexts.\",\n",
    "      \"reason_of_score\": \"The phrasal verb is used appropriately, explaining its different meanings based on context, enhancing understanding.\"\n",
    "    },\n",
    "    \"Score\": 0.75\n",
    "  },\n",
    "  {\n",
    "    \"FoundedEntity\": {\n",
    "      \"Entity.entity\": \"put off\",\n",
    "      \"sub_type\": \"phrasalVerb\",\n",
    "      \"usage_example\": \"\"putoff\" means to postpone or delay.\",\n",
    "      \"context_from_dialogue\": \"The tutor is giving examples of phrasal verbs to the student.\",\n",
    "      \"reason_of_score\": \"The phrase is used correctly, showcasing its meaning as part of educational content on phrasal verbs.\"\n",
    "    },\n",
    "    \"Score\": 0.70\n",
    "  },\n",
    "  {\n",
    "    \"FoundedEntity\": {\n",
    "      \"Entity.entity\": \"run into\",\n",
    "      \"sub_type\": \"phrasalVerb\",\n",
    "      \"usage_example\": \"\"runinto\" means to encounter someone unexpectedly.\",\n",
    "      \"context_from_dialogue\": \"The tutor is explaining the meaning of various phrasal verbs.\",\n",
    "      \"reason_of_score\": \"The usage fits perfectly in the educational context where the tutor explains the meaning of the phrasal verb.\"\n",
    "    },\n",
    "    \"Score\": 0.80\n",
    "  },\n",
    "  {\n",
    "    \"FoundedEntity\": {\n",
    "      \"Entity.entity\": \"tongue-twister\",\n",
    "      \"sub_type\": \"vocabulary\",\n",
    "      \"usage_example\": \"\"Thesixthsicksheik's sixth sheep'ssick.\" That's a tongue-twister!\",\n",
    "      \"context_from_dialogue\": \"The student recognizes the complexity of the sentence the tutor asked them to repeat.\",\n",
    "      \"reason_of_score\": \"The term is used correctly, identifying a specific type of sentence designed to be difficult to articulate.\"\n",
    "    },\n",
    "    \"Score\": 0.90\n",
    "  },\n",
    "  {\n",
    "    \"FoundedEntity\": {\n",
    "      \"Entity.entity\": \"practice makes perfect\",\n",
    "      \"sub_type\": \"idiom\",\n",
    "      \"usage_example\": \"You're welcome! Remember, practice makes perfect.\",\n",
    "      \"context_from_dialogue\": \"The tutor encourages the student to keep practicing to improve.\",\n",
    "      \"reason_of_score\": \"The idiom is used in a motivational context, which is a common and appropriate use, encouraging continued effort and improvement.\"\n",
    "    },\n",
    "    \"Score\": 0.95\n",
    "  }\n",
    "]\n",
    "\n",
    "you have to print this [example] format.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_assistant = \"\"\"\n",
    "The Entity example for few shot\n",
    "``` ex.1\n",
    "  {\n",
    "    \"entity\": \"Today\",\n",
    "    \"sub_type\": \"vocabulary\",\n",
    "    \"cefr\": \"B2\",\n",
    "    \"category_main\": \"Society and Relationship\",\n",
    "    \"category_sub\": \"Travel and Places\",\n",
    "    \"category_detail\": \"Religion\",\n",
    "    \"usage_example\": \"The museum displayed aboriginal art from Australia.\",\n",
    "    \"explanation\": \"Inhabiting or existing in a land from the earliest times or from before the arrival of colonists.\"\n",
    "  }\n",
    "  ```\n",
    "  ``` ex.2\n",
    "  {\n",
    "    \"entity\": \"Lastly\",\n",
    "    \"sub_type\": \"vocabulary\",\n",
    "    \"cefr\": \"A2\",\n",
    "    \"category_main\": \"Society and Relationship\",\n",
    "    \"category_sub\": \"Culture and Customs\",\n",
    "    \"category_detail\": \"Description\",\n",
    "    \"usage_example\": \"My parents allow me to go to the concert.\",\n",
    "    \"explanation\": \"Allow means to give (someone) permission to do something.\"\n",
    "  }\n",
    "  ```\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog = \"\"\"\n",
    "{\n",
    "    \"idx\": 1,\n",
    "    \"class_type\": \"reading\",\n",
    "    \"student_level\": \"A1\",\n",
    "    \"dialogue\": {\n",
    "        \"0\": [\n",
    "            {\n",
    "                \"Tutor\": \"Today, we're going to read a story. Are you ready?\"\n",
    "            },\n",
    "            {\n",
    "                \"Student\": \"Yes, I'm ready.\"\n",
    "            },\n",
    "            {\n",
    "                \"Tutor\": \"Great! Let's start. \\\"Little Red Riding Hood went to visit her grandmother.\\\" What did Little Red Riding Hood do?\"\n",
    "            },\n",
    "            {\n",
    "                \"Student\": \"She went to visit her grandmother.\"\n",
    "            },\n",
    "            {\n",
    "                \"Tutor\": \"That's correct. Now, let's move on. \\\"She met a wolf in the woods.\\\" Who did Little Red Riding Hood meet?\"\n",
    "            },\n",
    "            {\n",
    "                \"Student\": \"She met a wolf in the woods.\"\n",
    "            },\n",
    "            {\n",
    "                \"Tutor\": \"Good job! Lastly, \\\"The wolf tricked her and ate her.\\\" What happened to Little Red Riding Hood?\"\n",
    "            },\n",
    "            {\n",
    "                \"Student\": \"The wolf tricked her and ate her.\"\n",
    "            },\n",
    "            {\n",
    "                \"Tutor\": \"Excellent! You understood the story very well. Can you tell me in your own words what happened in the story?\"\n",
    "            },\n",
    "            {\n",
    "                \"Student\": \"Little Red Riding Hood went to visit her grandmother. She met a wolf in the woods. The wolf tricked her and ate her.\"\n",
    "            },\n",
    "            {\n",
    "                \"Tutor\": \"Very good! You summarized the story perfectly. Keep practicing and you'll become even better at understanding and comprehending stories.\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": lexical_system\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": lexical_assistant\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": dialog\n",
    "    }\n",
    "  ],\n",
    "  temperature=0,\n",
    "  max_tokens=700,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"FoundedEntity\": {\n",
      "      \"Entity.entity\": \"Little Red Riding Hood\",\n",
      "      \"sub_type\": \"vocabulary\",\n",
      "      \"usage_example\": \"Little Red Riding Hood went to visit her grandmother.\",\n",
      "      \"context_from_dialogue\": \"The tutor introduces the story of Little Red Riding Hood.\",\n",
      "      \"reason_of_score\": \"The vocabulary is used correctly within the context, referring to the main character of the story.\"\n",
      "    },\n",
      "    \"Score\": 0.85\n",
      "  },\n",
      "  {\n",
      "    \"FoundedEntity\": {\n",
      "      \"Entity.entity\": \"grandmother\",\n",
      "      \"sub_type\": \"vocabulary\",\n",
      "      \"usage_example\": \"Little Red Riding Hood went to visit her grandmother.\",\n",
      "      \"context_from_dialogue\": \"The tutor mentions the character of Little Red Riding Hood's grandmother.\",\n",
      "      \"reason_of_score\": \"The vocabulary is used correctly within the context, referring to a family member of the main character.\"\n",
      "    },\n",
      "    \"Score\": 0.80\n",
      "  },\n",
      "  {\n",
      "    \"FoundedEntity\": {\n",
      "      \"Entity.entity\": \"wolf\",\n",
      "      \"sub_type\": \"vocabulary\",\n",
      "      \"usage_example\": \"She met a wolf in the woods.\",\n",
      "      \"context_from_dialogue\": \"The tutor mentions the encounter of Little Red Riding Hood with a wolf.\",\n",
      "      \"reason_of_score\": \"The vocabulary is used correctly within the context, referring to a predatory animal in the story.\"\n",
      "    },\n",
      "    \"Score\": 0.75\n",
      "  },\n",
      "  {\n",
      "    \"FoundedEntity\": {\n",
      "      \"Entity.entity\": \"woods\",\n",
      "      \"sub_type\": \"vocabulary\",\n",
      "      \"usage_example\": \"She met a wolf in the woods.\",\n",
      "      \"context_from_dialogue\": \"The tutor mentions the location where Little Red Riding Hood encountered the wolf.\",\n",
      "      \"reason_of_score\": \"The vocabulary is used correctly within the context, referring to a forested area.\"\n",
      "    },\n",
      "    \"Score\": 0.70\n",
      "  },\n",
      "  {\n",
      "    \"FoundedEntity\": {\n",
      "      \"Entity.entity\": \"tricked\",\n",
      "      \"sub_type\": \"vocabulary\",\n",
      "      \"usage_example\": \"The wolf tricked her and ate her.\",\n",
      "      \"context_from_dialogue\": \"The tutor describes the action of the wolf deceiving Little Red Riding Hood.\",\n",
      "      \"reason_of_score\": \"The vocabulary is used correctly within the context, indicating the act of deceiving or fooling someone.\"\n",
      "    },\n",
      "    \"Score\": 0.75\n",
      "  },\n",
      "  {\n",
      "    \"FoundedEntity\": {\n",
      "      \"Entity.entity\": \"ate\",\n",
      "      \"sub_type\": \"vocabulary\",\n",
      "      \"usage_example\": \"The wolf tricked her and ate her.\",\n",
      "      \"context_from_dialogue\": \"The tutor mentions the outcome of the wolf's actions towards Little Red Riding Hood.\",\n",
      "      \"reason_of_score\": \"The vocabulary is used correctly within the context, indicating the act of consuming food.\"\n",
      "    },\n",
      "    \"Score\": 0.70\n",
      "  },\n",
      "  {\n",
      "    \"FoundedEntity\": {\n",
      "      \"Entity.entity\": \"story\",\n",
      "      \"sub_type\": \"vocabulary\",\n",
      "      \"usage_example\": \"Can you tell me in your own words what happened in the story?\",\n",
      "      \"context_from_dialogue\": \"The tutor asks the student to summarize the events of the story.\",\n",
      "      \"reason_of_score\": \"The vocabulary is used correctly within the context, referring to a narrative or account of events.\"\n",
      "    },\n",
      "    \"Score\n"
     ]
    }
   ],
   "source": [
    "# `response`에서 JSON 형식의 문자열을 추출하는 함수\n",
    "def extract_json_string(response):\n",
    "    # 모델의 응답에서 메시지 리스트 추출\n",
    "    messages = response.get('choices', [])[0].get('message', {}).get('content')\n",
    "    return messages\n",
    "\n",
    "# 위에서 생성한 `response` 객체를 사용하여 JSON 문자열 추출\n",
    "json_string = extract_json_string(response)\n",
    "print(json_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"FoundedEntity\": {\\n      \"Entity.entity\": \"Little Red Riding Hood\",\\n      \"sub_type\": \"vocabulary\",\\n      \"usage_example\": \"Little Red Riding Hood went to visit her grandmother.\",\\n      \"context_from_dialogue\": \"The tutor introduces the story of Little Red Riding Hood.\",\\n      \"reason_of_score\": \"The vocabulary is used correctly within the context, referring to the main character of the story.\"\\n    },\\n    \"Score\": 0.85\\n  },\\n  {\\n    \"FoundedEntity\": {\\n      \"Entity.entity\": \"grandmother\",\\n      \"sub_type\": \"vocabulary\",\\n      \"usage_example\": \"Little Red Riding Hood went to visit her grandmother.\",\\n      \"context_from_dialogue\": \"The tutor mentions the character of Little Red Riding Hood\\'s grandmother.\",\\n      \"reason_of_score\": \"The vocabulary is used correctly within the context, referring to a family member of the main character.\"\\n    },\\n    \"Score\": 0.80\\n  },\\n  {\\n    \"FoundedEntity\": {\\n      \"Entity.entity\": \"wolf\",\\n      \"sub_type\": \"vocabulary\",\\n      \"usage_example\": \"She met a wolf in the woods.\",\\n      \"context_from_dialogue\": \"The tutor mentions the encounter of Little Red Riding Hood with a wolf.\",\\n      \"reason_of_score\": \"The vocabulary is used correctly within the context, referring to a predatory animal in the story.\"\\n    },\\n    \"Score\": 0.75\\n  },\\n  {\\n    \"FoundedEntity\": {\\n      \"Entity.entity\": \"woods\",\\n      \"sub_type\": \"vocabulary\",\\n      \"usage_example\": \"She met a wolf in the woods.\",\\n      \"context_from_dialogue\": \"The tutor mentions the location where Little Red Riding Hood encountered the wolf.\",\\n      \"reason_of_score\": \"The vocabulary is used correctly within the context, referring to a forested area.\"\\n    },\\n    \"Score\": 0.70\\n  },\\n  {\\n    \"FoundedEntity\": {\\n      \"Entity.entity\": \"tricked\",\\n      \"sub_type\": \"vocabulary\",\\n      \"usage_example\": \"The wolf tricked her and ate her.\",\\n      \"context_from_dialogue\": \"The tutor describes the action of the wolf deceiving Little Red Riding Hood.\",\\n      \"reason_of_score\": \"The vocabulary is used correctly within the context, indicating the act of deceiving or fooling someone.\"\\n    },\\n    \"Score\": 0.75\\n  },\\n  {\\n    \"FoundedEntity\": {\\n      \"Entity.entity\": \"ate\",\\n      \"sub_type\": \"vocabulary\",\\n      \"usage_example\": \"The wolf tricked her and ate her.\",\\n      \"context_from_dialogue\": \"The tutor mentions the outcome of the wolf\\'s actions towards Little Red Riding Hood.\",\\n      \"reason_of_score\": \"The vocabulary is used correctly within the context, indicating the act of consuming food.\"\\n    },\\n    \"Score\": 0.70\\n  },\\n  {\\n    \"FoundedEntity\": {\\n      \"Entity.entity\": \"story\",\\n      \"sub_type\": \"vocabulary\",\\n      \"usage_example\": \"Can you tell me in your own words what happened in the story?\",\\n      \"context_from_dialogue\": \"The tutor asks the student to summarize the events of the story.\",\\n      \"reason_of_score\": \"The vocabulary is used correctly within the context, referring to a narrative or account of events.\"\\n    },\\n    \"Score'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     corrected_json_string \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread()\n\u001b[1;32m     19\u001b[0m \u001b[39m# Load the JSON string into a Python object\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m json_entities \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(corrected_json_string)\n\u001b[1;32m     22\u001b[0m \u001b[39m# Load model from HuggingFace Hub (this should be done outside of your loop or function to avoid reloading)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39msentence-transformers/all-MiniLM-L6-v2\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/sbert/lib/python3.8/json/__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[39mdel\u001b[39;00m kw[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 357\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/anaconda3/envs/sbert/lib/python3.8/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/anaconda3/envs/sbert/lib/python3.8/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "from scipy.spatial.distance import cosine\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Load the embeddings from the CSV file\n",
    "embeddings_df = pd.read_csv('/Users/marketdesigners/Documents/GitHub/sentencec-bert/data/entity_embeddings_sample.csv')  # Update the path to where the file is stored\n",
    "\n",
    "# After editing and saving the JSON string in a text file\n",
    "file_path = '/Users/marketdesigners/Documents/GitHub/sentencec-bert/data/extract_entity.txt'  # Replace with the actual file path\n",
    "\n",
    "# Read the corrected JSON string from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    corrected_json_string = file.read()\n",
    "\n",
    "# Load the JSON string into a Python object\n",
    "json_entities = json.loads(corrected_json_string)\n",
    "\n",
    "# Load model from HuggingFace Hub (this should be done outside of your loop or function to avoid reloading)\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Define mean pooling function\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Function to calculate cosine similarity between two vectors\n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    # Cosine similarity is calculated as 1 - cosine distance\n",
    "    return 1 - cosine(embedding1, embedding2)\n",
    "\n",
    "# Concatenate all text data from json_entities to create a large string per entity for encoding\n",
    "concatenated_entity_texts = [\n",
    "    ' '.join([str(value) for key, value in entity.items() if isinstance(value, str)])\n",
    "    for entity in json_entities\n",
    "]\n",
    "\n",
    "# Tokenize and encode the concatenated text data\n",
    "encoded_inputs = tokenizer(concatenated_entity_texts, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings for json_entities\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_inputs)\n",
    "\n",
    "# Perform pooling to get sentence embeddings\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_inputs['attention_mask'])\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "# Convert DataFrame 'Embedding' column from stringified lists to actual lists\n",
    "embeddings_df['Embedding'] = embeddings_df['Embedding'].apply(json.loads)\n",
    "\n",
    "# Function to find the most similar entity from embeddings.csv for each json entity\n",
    "def find_most_similar_entities(sentence_embeddings, embeddings_df):\n",
    "    most_similar_entities = []\n",
    "    for embedding in tqdm(sentence_embeddings, desc='Calculating similarities'):\n",
    "        # Calculate cosine similarity with each entity in embeddings.csv\n",
    "        similarities = embeddings_df['Embedding'].apply(lambda emb: calculate_cosine_similarity(embedding, emb))\n",
    "        \n",
    "        # Get the index of the most similar entity\n",
    "        most_similar_index = similarities.idxmax()\n",
    "        \n",
    "        # Get the corresponding entity from embeddings.csv\n",
    "        most_similar_entity = embeddings_df.iloc[most_similar_index]['Entity']\n",
    "        \n",
    "        # Append the most similar entity to the list\n",
    "        most_similar_entities.append(most_similar_entity)\n",
    "    \n",
    "    return most_similar_entities\n",
    "\n",
    "# Use the function to find the most similar entities\n",
    "most_similar_entities = find_most_similar_entities(sentence_embeddings, embeddings_df)\n",
    "\n",
    "# Print the results\n",
    "for entity_text, most_similar in zip(concatenated_entity_texts, most_similar_entities):\n",
    "    print(f\"Original entity text: {entity_text}\")\n",
    "    print(f\"Most similar entity from embeddings.csv: {most_similar}\")\n",
    "    print(\"-------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
